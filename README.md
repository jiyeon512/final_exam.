# final_exam.
컴퓨터 알고리즘 기말고사 


#  유전자 (Genetic Algorithm, GA)알고리즘

: 다윈의 진화론으로부터 창안된 해 탐색 알고리즘이다. 

: '적자생존'의 개념을 최적화 문제를 해결하는데 적용된다.

![image](https://user-images.githubusercontent.com/101514626/173842547-eb3e6945-8349-45d5-b509-e75a02a7b9a1.png)

GA 사이클


![image](https://user-images.githubusercontent.com/101514626/173842681-5959ff49-b9a2-4c3b-961b-f8ce15e0b603.png)



▪ 여러 개의 해를 임의로 생성하여 이들을 초기 세대 G0로 놓고 repeat-루프에서 현재 세대의 해로부터 다음 세대의 해를 생성해가며, 루프가 끝났을 때의 마지막 세대에서 가장 우수한 해를 반환한다. 이 해들은 repeat-루프의 반복적인 수행을 통해서 최적해 또는 최적해에 근접한 해가 될 수 있으므로 후보해(candidate solution)라고 부른다. 


후보해
![image](https://user-images.githubusercontent.com/101514626/173843054-1bbdb385-6d10-420a-a057-a8baf47ecf90.png)

후보해의 수

시작 도시를 제외한 4개의 도시를 일렬로 나열하는 방법의 수: (5-1)! = 4! = 24

n개의 도시의 후보해 수 = (n-1)!


후보해의 평가
![image](https://user-images.githubusercontent.com/101514626/173843293-3884bae0-7afe-457b-9d7f-fc2226b16333.png)
적합도


후보해의 값 = 후보해의 적합도(FItness value)

후보해 중에서 최적해의 값에 근접한 적합도를 가진 후보해를 '우수한' 해라고 부른다.


▪ GA연산에는 선택(selection) 연산, 교차(crossover) 연산, 돌연변이(mutation) 연산이 있다.



1. 선택 연산: 현재 세대의 후보해 중에서 우수한 후보해를 선택하는 연산

현재 세대에 n개의 후보해가 있으면 이들 중에서 우수한 후보해는 중복되어 선택될 수 있고, 적합도가 상대적으로 낮은 후보해들은 선택되지 않을 수도 있다. 이렇게 선택된  후보해의 수는 n개로 유지된다. 이러한 선택은 '적자생존' 개념을 모방한 것이다. 



• 룰렛 휠 선택

룰렛 휠(roulette wheel) 방법

: 각 후보해의 적합도에 비례하여 원반의 면적을 할당하고, 원반을 회전 시켜서 원반이 멈추었을 때 핀이 가리키는 후보해를 선택한다. 면적이 넓은 후보해가 선택될 확률이 높다.

![image](https://user-images.githubusercontent.com/101514626/173843716-ba8436c2-1fce-4790-b0b4-19677debe72f.png)


각 후보해의 원반 면적은 (후보해의 적합도 / 모든 후보해의 적합도의 합)에 비례한다

예제에서 모든 적합도의 합이 20 = (10 + 5 + 3 + 2)이므로, 후보해 1의 면적은 10/20 = 50%, 후보해 2의 면적은 5/20 = 25%, 후보해 3의 면적은 3/20 = 15%, 후보해 4의 면적은 2/20 = 10%이다. 

현재 4개의 후보해가 있으므로, 원반을 4번 돌리고 회전이 멈추었을 때 핀이 가리키는 후보해를 각각 선택한다


• 토너먼트 선택

1. 후보해 집합에서 k개의 후보해를 랜덤하게 선택한다.

2. 선택된 k개 중에서 가장 적합도가 우수한 해를 선택한다.

3. 선택 후 k개를 모두 후보해 집단에 넣는다.



• 이진 토너먼트 선택

k=2, 가장 많이 쓰이는 선택연산



2. 교차 연산

: 선택 연산을 수행한 후의 후보해 사이에 수행되는데, 이는 염색체가 교차하는 것을 모방한 것이다.

![image](https://user-images.githubusercontent.com/101514626/173844064-3a849fa8-5008-4d95-93b7-e4d51b3fcb6a.png)


1-점(point)교차 연산

: 랜덤하게 교차할 점을 선택한 후, 두 개의 후보해를 교차점을 기준으로 뒷부분을 서로 교환한다.

![image](https://user-images.githubusercontent.com/101514626/173844157-a7fa6987-4e9d-4e20-8a33-995320b7b133.png)
후보해가 길면, 여러 개의 교차점을 랜덤하게 정하여 교차 연산을 할 수도 있다.


교차 연산의 목적: 선택 연산을 통해 얻은 우수한 후보해보다 우수한 후보해를 생성하기 위해

교차율(Crossover Rate): 문제에 따라 교차 연산을 수행할 후보해의 수를 조절하는데, 이를 교차율이라고 한다. 일반적으로 교차율은 0.2~1.0 범위에서 정한다. 


3. 돌연변이 연산

: 교차 연산 수행 후에 돌연변이 연산 수행

: 아주 작은 확률로 후보해의 일부분을 임의로 변형시킨다. 이 확률을 돌연변이율(Mutation Rate)이라고 하며, 일반적으로 (1/PopSize)~(1/Length)의 범위에서 사용한다. PopSize란 모집단 크기로서 한 세대의 후보해의 수이다. Length란 후보해를 이진 표현으로 했을 경우의 bit 수이다. 돌연변이가 수행된 후에 후보해의 적합도가 오히려 나빠질 수도 있다. 


▪ 돌연변이 연산 예제

두 번째 bit가 0에서 1로 돌연변이된 것을 보여준다.

![image](https://user-images.githubusercontent.com/101514626/173844458-44ea7fb0-b0b7-45ec-a735-09f612bbd652.png)



▪ 돌연변이 연산의 목적

: 다음 세대에 돌연변이가 이루어진 후보해와 다른 후보해를 교차 연산함으로써 이후 세대에서 매우 우수한 후보해를 생성하기 위해

![image](https://user-images.githubusercontent.com/101514626/173844639-0e6b1c82-91a5-4386-b150-2deede1af3aa.png)

종료 조건

유전자 알고리즘이 항상 최적해를 찾는다는 보장이 없기 때문에 종료 조건은 일정하지 않다. 일반적으로 알고리즘을 수행시키면서 더 이상 우수한 해가 출현하지 않으면 알고리즘을 종료한다. 


GA 수행과정
![image](https://user-images.githubusercontent.com/101514626/173844796-a78da41a-1aa2-4172-b156-21c84bc5da65.png)

두 번째 세대의 후보해에 대한 적합도
![image](https://user-images.githubusercontent.com/101514626/173844869-3ac71ffb-0232-4509-8a4a-f011ebe2b39d.png)
알고리즘 종료

충분한 세대를 거쳐 repeat-루프를 더 수행하여 후보해의 적합도가 변하지 않으면 알고리즘을 종료한다. 후보해 중에서 가장 적합도가 높은 후보해를 리턴한다. 

TSP를 위한 GA

여행자 문제를 해결할 때 GA을 적용하기 위해 사용되는 2가지의 교차 연산 

2점 교차 연산, 사이클 교차 연산

여행자 문제의 후보해: 시작 도시부터 각 도시를 중복없이 나열하여 만들어진다.


2점-교차 연산

임의의 2점을 정한 후, 가운데 부분을 서로 교환한다. 이후 중복되는 도시(점선 박스 내의 도시)를 현재 후보해에 없는 도시로 차례로 바꾼다. 
![image](https://user-images.githubusercontent.com/101514626/173845086-fad0a9ad-624a-4457-8ce4-6ec7bb5d600f.png)

후보해 1에 대해 가운데 부분을 제외한 부분에 있는 H, B, A를 각각 C, D, E로 바꾸고 후보해 2에 대해 가운데 부분을 제외한 부분에 있는 C, D, E를 각각 H, B, A로 바꾼다. 



▪ 사이클 교차 연산

후보해 1에서 임의의 도시 C를 선택한 후, C와 같은 위치에 있는 후보해 2의 도시 D와 바꾼다. ①

바꾼 후에는 후보해 1에는 C가 없고, D가 2개 존재한다. 이를 해결하기 위해 후보해 1에 원래부터 있었던 D를 후보해 2에 D와 같은 위치에 있는 G와 바꾼다. ②

이렇게 반복하여 C가 후보해 2로부터 후보해 1로 바뀌게 되면 교차 연산을 마친다. 

![image](https://user-images.githubusercontent.com/101514626/173845234-d4cfac8c-251b-4d2b-bcec-244ba4383fc1.png)

▪ 다양한 실험 필요

유전자 알고리즘은  대부분의 경우 실제로 적지 않은 실험이 필요하다. 주어진 문제에 대해서 모집단의 크기, 교차율, 도련변이율 등과 같은 파라미터가 다양한 실험을 통해서 조절되어야 한다. repeat-루프의 종료 조건도 실험을 통해서 결정할 수밖에 없다. 또한 다양한 선택 연산과 교차 연산 중에서 어떤 연산이 주어진 문제에 적절한지도 많은 실험을 통해서 결정해야한다. 


▪ 유전자 알고리즘 특징

문제의 최적해를 알 수 없고, 기존의 어느 알고리즘으로도 해결하기 어려운 경우에, 최적해에 가까운 해를 찾는데 매우 적절한 알고리즘이다. 유전자 알고리즘이 최적해를 반드시 찾는다는 보장은 없으나 대부분의 경우 매우 우수한 해를 찾는다. 


4. 모의 담금질 기법 

모의 담금질 기법: 높은 온도에서 액체 상태인 물질이 온도가 점차 낮아지면서 결정체로 변하는 과정을 모방한 해 탐색 알고리즘이다. 융용 상태에서는 물질의 분자가 자율이 움직이는데 이를 모방하여, 해를 탐색하는 과정도 특정한 패턴 없이 이루어진다. 온도가 점점 낮아지면 분자의 움직임이 점점 줄어들어 결정체가 되는데, 해 탐색 과정도 이와 유사하게 점점 더 규칙적인 방식으로 이루어진


▪ 이웃해

: 이러한 방식으로 해를 탐색하려면, 후보해에 대해 이웃하는 해(이웃해)를 정의하여야 한다. 아래의 오른쪽 그림에서 각 점은 후보해이고 아래쪽에 위치한 해가 위쪽에 있는 해보다 우수한 해이다. 또한 2개의 후보해 사이의 화살표는 이 후보해들이 서로 이웃하는 관계임을 나타낸다. 

![image](https://user-images.githubusercontent.com/101514626/173845570-82d2ba58-9e2a-4dfa-b0d7-49e0bf4ff798.png)


▪ 탐색 과정

높은 T에서의 초기 탐색은 최솟값을 찾는데도 불구하고 확률 개념을 도입하여 현재 해의 이웃해 중에서 현재 해보다 '나쁜' 해로 (위 방향으로) 이동하는 자유로움을 보일 수도 있다. T가 낮아지면서 점차 탐색은 아래 방향으로 향한다. T가 낮아질수록 위 방향으로 이동하는 확률이 점차 작아진다. 그림에서 처음 도착한 골자기 (지역 최적해, local optimum)에서 더 이상 아래로 탐색할 수 없는 상태에 이르렀을 때 '운 좋게' 위 방향으로 탐색하다가 전역 최적해(global optimum)를 찾은 것을 보여준다. 


▪ 모의 담금질 기법의 특성

유전자 알고리즘과 마찬가지로 모의 담금질 기법도 항상 전역 최적해를 찾아준다는 보장은 없다. 모의 담금질 기법의 또 하나의 특징은 하나의 초기해로부터 탐색이 진행된다는 것이다. 반면에 유전자 알고리즘은 여러개의 후보해를 한 세대로 하여 탐색을 수행한다. 


SimulatedAnnealing 알고리즘
![image](https://user-images.githubusercontent.com/101514626/173845783-91a15557-fb51-4129-9d29-b73ecbbb98c3.png)


▪ 자유롭게 탐색할 확률 p

line 9~11: s'가 s보다 우수하지 않더fkeh 0~1 사이에서 랜덤하게 선택한 수 q가 확률 p보다 작으면, s'가 현재 해인 s가 될 기회를 준다. 이 기회가 그림에서 최솟값을 찾는데도 불구하고 위쪽에 위치한 이웃해로 탐색을 진행한다. p는 자유롭게 탐색할 확률이다. 

![image](https://user-images.githubusercontent.com/101514626/173845897-2a055d8d-708a-4597-938c-c8e9b69b2d5e.png)

▪ 냉각률

line 12: T를 일정 비율 α로 감소시킨다. 실제로 0.8 ≤ α ≤ 0.99 범위에서 미리 정한 냉각률 α(cooling ratio)를 T에 곱하여 새로운 T를 계산한다. 일반적으로 0.99에 가까운 수로 선택한다. 



▪ 확률 p 조절

모의 담금질 기법은 T가 높을 때부터 점점 낮아지는 것을 확률 p에 반영시켜서 초기에는 탐색이 자유롭다가 점점 규칙적이 되도록 한다. 확률 p는 T에 따라서 변해야 한다. T가 높을 땐, p를 크게 하고, T가 0이 되면, p를 0으로 만들어서 나쁜 이웃해 s'가 s가 되지 못하도록 한다. s'와 s의 값의 차이 d에 따라 p를 조절한다. d 값이 크면, p를 작게 하고, d 값이 작으면, p를 크게 한다. 이렇게 하는 이유는 값의 차이가 큼에도 불구하고 p를 크게하면 그 동안 탐색한 결과가 무시되어 랜덤하게 탐색하는 결과를 낳기 때문이다. 


▪ 확률 p

두 가지 요소를 종합한 확률 p 

p = 1 / ed/T = e-d/T​

T는 큰 값에서 0까지 변하고, d는 s'와 s의 값의 차이이다.



▪ 이웃해 정의

TSP의 이웃해 정의 3가지 예

1. 삽입(Insertion), 2. 교환(Switching), 3. 반전(Inversion)


• 삽입(Insertion)

2개의 도시를 랜덤하게 선택한 후에, 두 번째 도시를 첫 번째 도시 옆으로 옮기고, 두 도시 사이의 도시들은 오른쪽으로 1칸씩 이동한다. 

![image](https://user-images.githubusercontent.com/101514626/173846223-f073f49d-91de-405b-aeac-f459ae729d24.png)


도시 B와 F가 랜덤하게 선택되었다면, F가 B의 바로 오른쪽으로 이동한 후, B와 F 사이의 C, D, E를 각각 오른쪽으로 1칸씩 이동한다.



• 교환(Switching)

2개의 도시를 랜덤하게 선택한 후에, 그 도시들의 위치를 서로 바꾼다.

![image](https://user-images.githubusercontent.com/101514626/173846520-35dcde00-740a-4530-a558-031af09bcb27.png)

도시 B와 F가 랜덤하게 선택되었다면, B와 F의 자리를 서로 바꾼다.


• 반전(Inversion)

2개의 도시를 랜덤하게 선
![image](https://user-images.githubusercontent.com/101514626/173846620-e4a06332-4232-4052-b381-06946e8a7ba5.png)

택한 후에, 그 두 도시 사이의 도시를 역순으로 만든다. 단, 선택된 두 도시도 반전에 포함시킨다.

도시 B와 E가 랜덤하게 선택되었다면, [B C D E]가 역순으로 [E D C B]로 바뀐다.


[요약]

• 백트래킹 기법(Backtracking): 해를 찾는 도중에 '막히면' 되돌아가서 다시 해를 찾아가는 기법으로 상태 공간 트리에서 깊이 우선 탐색(Depth First Search)으로 해를 찾는 알고리즘

백트래킹 기법의 시간복잡도는 상태 곤간 트리의 노드 수에 비례하고, 이는 모든 경우를 다 검사하여 해를 찾는 완전 탐색 시간 복잡도와 같다. 그러나 일반적으로 백트래킹 기법은 '가지치기'하므로 완전 탐색보다 훨씬 효율적이다. 


• 분기 한정 기법: 상태 공간 트리의 각 노드(상태)에 특정한 값(한정값)을 부여하고, 노드의 한정값을 활용하여 가지치기를 함으로서 백트래킹 기법보다 빠르게 해를 찾는다.

분기 한정 기법에서는 가장 우수한 한정값을 가진 노드를 먼저 탐색하는 최선 우선 탐색(Best First Search)으로 해를 찾는다.



• 유전자 알고리즘: 다윈의 진화론으로부터 고안된 해 탐색 알고리즘. '적자생존 개념을 최적화 문제를 해결하는데 적용한 것이다.

유전자 알고리즘은 여러 개의 해를 임의로 생성하여 이들에 대해 선택, 교차, 돌연변이 연산을 반복 수행하여 마지막에 가장 우수한 해를 리턴한다.

유전자 알고리즘은 문제의 최적해를 알 수 없고, 기존의 어느 알고리즘으로도 해결하기 어려운 경우에, 최적해에 가가운 해를 찾는데 매우 적절한 알고리즘이다.


• 모의 담금질(Simulated Annealing) 알고리즘: 높은 온도에서 액체 상태인 물질이 온도가 점차 낮아지면서 결정체로 변하는 과정을 모방한 해 탐색 알고리즘

유전자 알고리즘과 마찬가지로 모의 담금질 기법도 항상 전역 최적해를 찾아준다는 보장은 없다. 





# 담금질 기법 

Simulated annealing (SA) is a generic probabilistic metaheuristic for the global optimization problem of locating a good approximation to the global optimum of a given function in a large search space. It is often used when the search space is discrete (e.g., all tours that visit a given set of cities). For certain problems, simulated annealing may be more efficient than exhaustive enumeration — provided that the goal is merely to find an acceptably good solution in a fixed amount of time, rather than the best possible solution.

![image](https://user-images.githubusercontent.com/101514626/173850122-eb28295a-10d8-42e6-af52-d7940a2ad1bf.png)

Simulated Annealing은 아주 어려운 문제를 풀기 위해 점진적으로 그 해(solution)에 가까운 방향으로 이동하되 적은 확률(0.05~0.5%)로 예상되는 해에 아주 먼 방향으로 이동해야 합니다.

예를 들어 산오르기를 들겠습니다.

수백개의 산들로 이루어진 산맥에서 가장 높은 산을 찾고 싶습니다. 
그런데 그 산이 어떤 산인지, 가장 높은 산의 높이가 얼마인지 전혀 모릅니다. 그리고 지금 가지고 있는 장비는 고도계 하나 뿐입니다. 
그리고 산에는 나무가 아주 울창해서 가장 높은 산은 커녕 어느 방향이 산봉우리인지도 모릅니다. 이러한 상황에서 우리가 할 수 있는 것은 주위를 보고서 현재 위치보다 좀 더 높은 곳으로 향하는 것이 제일 무난한 방법입니다. 
그런데 이런 식으로 가면 결국은 한 산봉우리에 올라갈 수는 있습니다. 그런데 그 산봉우리가 가장 높은 산일 확률은 1/(산봉우리의 수) 입니다. 매우 낮은 확률입니다.



시뮬레이티드 어닐링은 가장 높은 산으로 갈 확률을 높이기 위해서 어느 정도 올라가다가 주사위를 굴립니다. 

그래서 특정한 수가 나오게 되면 (특정 확률로) 절벽이나 비탈 아래로 미끌어집니다. 

어느 정도 미끌어진 뒤에 거기서부터 다시 올라가기 시작합니다. 이와 같이 가끔씩 미끌어지면 어떤 산봉우리에 올라가는데 걸리는 시간은 굉장히 오래 걸리지만 아주 높은 산봉우리에 올라갈 가능성이 훨씬 높아집니다.



▪ Simulated annealing은 커다란 탐색공간에서 주어진 함수의 전역 최적점 (global optimum) 에 대한 훌륭한 근사치를 찾으려고 하는 전역최적화 (global optimization) 문제에 대한 일반적인 확률적 휴리스틱 (probabilistic heuristic) 접근방식이다. 이 방법은 1983년에 S. Kirkpatrick, C. D. Gelatt, M. P. Vecchi, 1985년에 V. Cerny이 각각 동시에 발명한 것이다.


그 명칭과 정신은 야금학(metallurgy)에서 담금질(annealing)에서 따온 것이다. 즉 결정체(crystals)의 크기를 크게하고 결함(defects)을 작게 하려고 금속에 열을 가하고 냉각시키는 속도를 조절하는(controlled cooling) 기술에서 따온 것이다.

열을 가하면 원자(atoms)는 최초의 위치 (내부 에너지의 국소 최적점; local minimum) 에서 떨어져 나가고 더 높은 에너지 상태로 정처없이 방황하게 된다. 서서히 냉각시키면 최초의 상태보다 더 낮은 내부 에너지를 가지는 환경을 찾을 수 있는 기회를 더 많이 가지게 된다.

![image](https://user-images.githubusercontent.com/101514626/173850901-4255763d-1dd8-4417-a1be-221dcdee94b9.png)

이러한 개념들은 고체의 물리적인 담금질과 아주 많은 경우의 수를 가진 조합 최적화 (Combinatorial Optimization) 문제 사이의 밀접한 관계에 의거한다. 
Simulated annealing은 신경망(Neural Network)의 구조를 갖는 것은 아니다. 
단지 이러한 개념으로 여러 다른 신경망의 학습과정을 변화시켜줄 수 있다. 실제 많은 신경망 시스템에서 학습한다는 개념은 minimization 과정으로 볼 수 있으며, 그것은 energy function이나 error function에서 downward 방향으로 간다는 것을 의미한다. 
하지만 그러한 경우 initial weight 값을 잘못 선택하면 local minimum 값에 빠지고 마는 경우가 생기게 된다. 
이러한 문제를 해결하기 위한 방안으로 simulated annealing 개념이 도입되었다.


금속의 담금질(annealing)이란 고체를 녹을 때까지 가열하고 난 후 그것을 완전한 격자 상태의 결정체가 될 때까지 식히는 물리적인 과정이다. 이런 과정 중에 그 고체의 자유 에너지(free energy)는 최소화된다. 오래 전부터의 경험에 의하면 고체화되는 과정에서 지역 최소점에 빠지지 않도록 하기 위해서는 조심스럽게 서서히 식혀야 한다.

금속재료 등을 가열한 후 서서히 냉각시켜 내부의 결함을 없애는 방법과 유사하여 시뮬레이티드 어닐링 (simulated annealing) 이라 부른다. 여기에서 중요한 것은 온도를 낮추어가는 방법이다. 온도를 너무 급속히 낮추면 평행상태를 이루어도 최소 에너지 상태에 도달할 확률이 적고, 너무 천천히 낮추면 최소 에너지에 도달할 확률은 커지지만 많은 반복을 필요로 하므로 시간이 많이 걸린다.

조합 최적화 (combinatorial optimization) 문제에서도 이와 유사한 과정을 정의할 수 있다. 
이 과정은 잠재적으로 매우 많은 해결방안 중에서 최소의 비용이 드는 해답을 구하는 문제로 공식화될 수 있다. 
우리는 여기서 비용 함수(cost function)와 자유 에너지 사이의 관계, 그리고 해답과 물리적인 상태의 관계를 정립함으로써 물리적인 담금질 과정의 시뮬레이션에 의거한 조합 최적화 문제의 해결 방안을 소개할 수 있는데 이러한 방법이 바로 Simulated Annealing이다.


이 방법의 두드러진 특징은 폭넓은 응용 가능성과 최상에 가까운 해답을 얻을 수 있다는 점이다. 
그러나 이 방법에도 상당히 큰 단점이 있다. 상당히 좋은 해답을 얻는데 걸리는 계산 시간이 엄청나게 길다는 점이다. 그러나 시뮬레이티드 어닐링 알고리즘의 구현시 필요한 엄청난 시간은 대규모 병렬처리 (massively parallel execution) 를 기반으로 하는 계산 모델을 사용함으로써 상당히 줄일 수 있는데 그러한 모델 중의 하나가 바로 볼쯔만 머신(Boltzmann Machine)이다.


이 테크닉은 Informed Search의 한 종류이며, (따라서 평가 함수를 잘 만들어야한다)

일종의 Greed Method인 Hill Climbing Method에 Heuristics을 적용한 것이다.

그 Heuristics에 대해서 알아보자.

일반적으로 Hill Climbing Method는 그저 현재 상태보다 다음 상태가 좋으면 이동하게 된다. 이는 Local Maxima (혹은 Minima)에 빠지기 쉽다. 

어떤 공이 언덕(Hill)을 내려가는 예를 보자.

![image](https://user-images.githubusercontent.com/101514626/173851606-a7177b8b-220f-4fc8-a73d-bcd3fe1994f6.png)

시작 위치에서 공을 굴리면, 공은 Local Minima에 빠질 것이다. (가속도는 생각하지 말도록 하자) 하지만 우리가 원하는 것은 Global Minima에 공이 도달하는 것이다. 하지만 Hill Climbing Method에 의해서는, 공은 현재 위치보다 높은 곳으로는 이동하지 않기 때문에, 위 그림과 같은 상황이 발생한다.

이 때, 이 언덕 전체를 살짝 흔들어주면 어떻게 될까? 공이 Local Minima를 겨우 빠져 나갈 정도로 흔들어 준다면, 공은 Global Minima에 도달할 수 있을 것이다. 이렇게 흔들어 주는 것이 Simulated Annealing에 적용된 Heuristics이다.

그럼 어느 정도로 흔들어야 하는가? Simulated Annealing에서는 처음에는 세게, 그리고 시간이 지날수록 점점 그 강도를 약하게 할 것을 권하고 있다. 
그리고 그 세기가 0이 되고 공이 더이상 움직이지 않는다면, 그 순간을 종료 시점으로 삼고 있다.


이 흔들어주는 세기는 담금질 기법에서 냉각 속도에 해당된다.


흔드는 것은 어떻게 구현하는가? Temperature에 비례하는 확률로 공을 좋지 않은 방향으로 보내는 것이다. 
위 그림에서, 공이 Local Minima에 빠졌을 때, 확률적으로 언덕을 올라가게 한다. 물론 올라가는 방향이 제일 시작위치 쪽일 수도 있다. 하지만 그쪽은 훨씬 높기 때문에, 올라가다가 도로 내려올 확률이 높다. (기본 방향은 아래쪽이며, 가끔씩 확률적으로 올라가므로)

물론 오른쪽으로 올라가다가도 그냥 내려올 수도 있으나, 적어도 왼쪽 언덕을 넘는 것보다는 오른쪽 언덕을 넘는 확률이 더 높을 것이다.


Temperature의 값은 시작할때 최대로, 그리고 이동할 때마다 일정 수치를 감소시키면 될 것이다. 이것은 나의 생각이다. 문제에 따라 달라질 수 있으며, 중요한건 갈수록 줄어들면 된다는 것.


반대의 경우인, 산을 등반하는 경우에도 그대로 적용된다. 이 때는 기본값은 올라가는 것이고, 가끔씩 확률적으로 내려간다.

다음은, Artificial Intelligence - A Modern Approach,

![image](https://user-images.githubusercontent.com/101514626/173852047-1124efd5-cad3-4878-8638-8db65470a299.png)


Schedule[t]라는 것은 Temperature를 정해주는 함수이다.

VALUE[] 라는 것은 평가 함수의 값이다. 위의 공이 내려가는 문제에서는 공의 높이가 목표 지점과 가까운 정도가 될 것이다. 

MAKE-NODE() 함수는 트리 구조 같은데서 노드를 만드는 것이다. 트린지 그래픈진 모르겠지만 중요한건 처음 시작 지점을 현재 위치로 잡는다는 의미 뿐일 것이다.

e는 오일러수 . 이는 대략 2.718281828459045235360287471352662497 의 값이다.
